{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy_Mkn9NwUZE"
   },
   "source": [
    "# Introduction to machine learning: Decision makings -- Active learning with microRNA Classification\n",
    "\n",
    "In this notebook, we illustrate the classification task on microRNA data and show active learning methods. We will go through: \n",
    "\n",
    "* Mirtron\n",
    "* Logistic regression\n",
    "* Active learning\n",
    "    * uncertainty sampling \n",
    "    * least confidence sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# the jupyter notebook is launched from your $HOME, change the working directory provided a username directory is created under /scratch/vp91\n",
    "os.chdir(os.path.expandvars(\"/scratch/vp91/$USER/RMIT-NCI-Week/intro_ml_decisions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-QPtD9rFVvQ"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np \n",
    "import random as python_random\n",
    "from tensorflow.keras.utils import normalize\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, auc, roc_curve, matthews_corrcoef, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6eH_chXafiE"
   },
   "outputs": [],
   "source": [
    "# To obtain reproducible result\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(123)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "python_random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mirtron Data \n",
    "\n",
    "What is MicroRNA:\n",
    "> from wiki: *MicroRNAs (miRNAs) are a class of non-coding RNAs that play important roles in regulating gene expression. The majority of miRNAs are transcribed from DNA sequences into primary miRNAs and processed into precursor miRNAs, and finally mature miRNAs.*\n",
    "\n",
    "What is Mirtron: \n",
    "> from wiki: *Mirtrons are a type of microRNAs that are located in the introns of the mRNA encoding host genes. These short hairpin introns formed via atypical miRNA biogenesis pathways. Mirtrons arise from the spliced-out introns and are known to function in gene expression.*\n",
    "\n",
    "data: https://github.com/rorbachg/Mirtrons/tree/master/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUORvQmXVgMt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "miRBase_df = pd.read_csv( \"Data/data.csv\")\n",
    "print(miRBase_df.shape)\n",
    "miRBase_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Helper functions\n",
    "\n",
    "First, we convert the hairpin_seq into K-mers, which are short subsequences of length k that are extracted from longer sequences, such as DNA or protein sequences. In bioinformatics, k-mers are commonly used to represent and analyze sequence data. The value of k determines the length of each subsequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmers_builder(sequences, ksize):\n",
    "    kmers = []\n",
    "    for seq in sequences:\n",
    "        n_kmer = len(seq) - ksize + 1\n",
    "        kmer = []\n",
    "        for i in range(n_kmer):\n",
    "            temp_kmer = seq[i:i + ksize]\n",
    "            kmer.append(temp_kmer)\n",
    "        kmers.append(kmer)\n",
    "    return kmers\n",
    "\n",
    "kmers_builder(['AGGUUG'],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we convert kmers into onehot encoding:\n",
    "One-hot encoding is a technique used to represent categorical variables as binary vectors. It is commonly employed in machine learning and data analysis tasks where categorical features need to be transformed into a numerical representation that algorithms can understand.\n",
    "\n",
    "Here's an example of how one-hot encoding can be applied to DNA sequences:\n",
    "\n",
    "Consider the DNA sequence \"ACTG\". Each character (nucleotide base) in the sequence is a category. To one-hot encode this sequence, we assign a binary vector representation to each base:\n",
    "\n",
    "* Adenine (A): [1, 0, 0, 0]\n",
    "* Cytosine (C): [0, 1, 0, 0]\n",
    "* Guanine (G): [0, 0, 1, 0]\n",
    "* Thymine (T): [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(sequences, k_mer):\n",
    "    encoded_data = []\n",
    "    n = len(sequences)\n",
    "    l = len(sequences[0])\n",
    "    for i in range(n):\n",
    "        data = []\n",
    "        for k in range(l):\n",
    "            seq = sequences[i][k]\n",
    "            letter = [0 for _ in range(4**k_mer)]\n",
    "            if seq == 0:\n",
    "                data.append(letter)\n",
    "            else:    \n",
    "                index = seq-1\n",
    "                letter[index] = 1\n",
    "                data.append(letter)\n",
    "        encoded_data.append(data)\n",
    "    \n",
    "    return np.array(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add evalaution method to evaluate the predictions from our model.\n",
    "1. Recall (Sensitivity): Recall measures the ability of a classification model to identify all positive instances correctly. It calculates the ratio of true positives to the sum of true positives and false negatives. In other words, it tells us how well the model identifies the positive cases among all the actual positive cases.\n",
    "\n",
    "2. Specificity: Specificity measures the ability of a classification model to correctly identify negative instances. It calculates the ratio of true negatives to the sum of true negatives and false positives. Specificity provides information about how well the model identifies the negative cases among all the actual negative cases.\n",
    "\n",
    "3. Area Under the Curve (AUC): AUC refers to the area under the Receiver Operating Characteristic (ROC) curve. The ROC curve represents the trade-off between the true positive rate (sensitivity) and the false positive rate. AUC provides a single value that represents the overall performance of a classification model. A higher AUC indicates better discrimination between positive and negative instances.\n",
    "\n",
    "4. F1 Score: F1 score is a measure of the model's accuracy by considering both precision and recall. It is the harmonic mean of precision and recall and provides a balanced evaluation metric. F1 score ranges from 0 to 1, with 1 being the best performance.\n",
    "\n",
    "5. Matthews Correlation Coefficient (MCC): MCC is a metric that takes into account true positives, true negatives, false positives, and false negatives. It is particularly useful when dealing with imbalanced datasets. MCC ranges from -1 to +1, where +1 indicates a perfect prediction, 0 indicates random prediction, and -1 indicates a complete disagreement between predictions and actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating(round_test, round_pre):\n",
    "    \n",
    "    # Confusion matrix\n",
    "    c = confusion_matrix(round_test, round_pre)\n",
    "\n",
    "    # Precision \n",
    "    p = precision_score(round_test, round_pre)\n",
    "\n",
    "    # Specificity\n",
    "    tn, fp, fn, tp = confusion_matrix(round_test, round_pre).ravel()\n",
    "    s =  tn / (tn+fp)\n",
    "\n",
    "    # AUC\n",
    "    fpr, tpr, _ = roc_curve(round_test, round_pre)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "\n",
    "    model_precision, model_recall, _ = precision_recall_curve(round_test, round_pre)\n",
    "    pr_auc_score = auc(model_recall, model_precision)\n",
    "\n",
    "    # Recall\n",
    "    r = recall_score(round_test, round_pre)\n",
    "\n",
    "    # Accuracy\n",
    "    a = accuracy_score(round_test,round_pre)\n",
    "\n",
    "    # F1 score\n",
    "    f1 = f1_score(round_test,round_pre)\n",
    "\n",
    "    # MCC\n",
    "    mcc = matthews_corrcoef(round_test, round_pre)\n",
    "\n",
    "    # cohen kappa score\n",
    "    cks = cohen_kappa_score(round_test,round_pre)\n",
    "\n",
    "    result_dic = {\n",
    "      'Recall': r,\n",
    "      'Specificity': s,\n",
    "      'AUC': auc_score,\n",
    "      'F-1': f1,\n",
    "      'Matthews Corrcoef': mcc\n",
    "    }\n",
    "    return result_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Logistic Regression\n",
    "\n",
    "Scikit-learn provides a straightforward and efficient implementation of logistic regression, a popular classification algorithm. By importing the LogisticRegression class from the sklearn.linear_model module, we can create an instance of the logistic regression model. We can then use the fit() method to train the model on our dataset, passing in the feature matrix and corresponding target labels. During the training process, scikit-learn optimizes the model's parameters using an appropriate solver, such as the default 'lbfgs' solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = mirtron_df.append(putative_mirtron_df,ignore_index=True)\n",
    "# df = df.append(canonical_miRNA_df, ignore_index=True)\n",
    "\n",
    "k_mer = 2\n",
    "max_len = 80\n",
    "miRNA_seq = miRBase_df[\"hairpin_seq\"]\n",
    "miRNA_kmer = kmers_builder(miRNA_seq, k_mer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(miRNA_kmer)\n",
    "vocab_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(miRNA_kmer)\n",
    "X = one_hot_encoding(pad_sequences(X, maxlen=max_len, padding='pre',truncating='pre'), k_mer) \n",
    "X = X.reshape(X.shape[0],-1)\n",
    "\n",
    "miRBase_df.loc[miRBase_df[\"class\"]==True,\"class\"] = 1\n",
    "miRBase_df.loc[miRBase_df[\"class\"]==False,\"class\"] = 0\n",
    "y = list(miRBase_df[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets (80% for train + val, 20% for test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of each set\n",
    "print(\"Train set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>TODO: Fit the logistic regression model on the training data. Make predictions (y_pred) on the test data and evalaute using the helper function above.\n",
    "</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your task here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning \n",
    "\n",
    "Now we move to an active learning setting, where we have a small part of data for pretrain, a pool of data for active/sequential querying, and then test how our model would performance on the test data. We test the uncertainty sampling methods (entrop, least confidence) and compare with random sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-train/val/test: 10/70/20\n",
    "\n",
    "# Split the dataset into train and test sets (80% for train + val, 20% for test)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the trainval set into train and validation sets (12.5% for val, 70% for train)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.92, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of each set\n",
    "print(\"Train set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "evaluating(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define active learning loop in the following, \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>TODO: your task is to fill in the two active learning uncertainty sampling policies (entropy, least confidence)\n",
    "</b>\n",
    "</div>\n",
    "\n",
    "As a reminder:\n",
    "    \n",
    "* Entropy: information-theoretic measure that represents the amount of information needed to “encode” a distribution\n",
    "$$x_{E N T}^*=\\underset{x}{\\operatorname{argmax}}-\\sum_i P\\left(y_i \\mid x ; \\theta\\right) \\log P\\left(y_i \\mid x ; \\theta\\right)$$\n",
    "\n",
    "* Least confidence: select the data point which we are predicting with least confidence\n",
    "$$x_{L C}^*=\\underset{x}{\\operatorname{argmin}} P\\left(y^* \\mid x ; \\theta\\right)$$\n",
    "where $y^*=\\operatorname{argmax}_y P(y \\mid x ; \\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AL_loop(X_train, y_train, X_val, y_val, X_test, y_test, policy = 'random', round = 100):\n",
    "    queries = []\n",
    "\n",
    "    pool_X = X_val.copy()\n",
    "    pool_y = y_val.copy()\n",
    "\n",
    "    new_X = X_train.copy()\n",
    "    new_y = y_train.copy()\n",
    "    \n",
    "    auc_scores = []\n",
    "\n",
    "    for i in range(round):\n",
    "        \n",
    "        model = LogisticRegression()\n",
    "        model.fit(new_X, new_y)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        score_dict = evaluating(y_test, y_pred)\n",
    "        auc_scores.append(score_dict['AUC'])\n",
    "\n",
    "        prob_dist = model.predict_proba(pool_X)\n",
    "        \n",
    "        if policy == 'entropy':\n",
    "            # ------------------------------- #\n",
    "            #       TODO: entropy policy      #\n",
    "        \n",
    "            #---------------------------------#\n",
    "        elif policy == 'leastconfidence':\n",
    "            # ------------------------------- #\n",
    "            #   TODO: least confidence policy #\n",
    "            #---------------------------------#\n",
    "        elif policy == 'random':\n",
    "            np.random.seed(0)\n",
    "            select_idx = np.random.choice(range(len(pool_X)))\n",
    "        else:\n",
    "            return NotImplementedError\n",
    "        \n",
    "        new_X = np.append(new_X,[pool_X[select_idx]], axis = 0)\n",
    "        new_y.append(pool_y[select_idx]) \n",
    "        \n",
    "        pool_X = np.delete(pool_X, select_idx, axis = 0)\n",
    "        pool_y = np.delete(pool_y, select_idx, axis = 0)\n",
    "        # print(len(X_val))\n",
    "    return auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# entropy\n",
    "from collections import defaultdict\n",
    "\n",
    "eva_dict = defaultdict(list) # key: policy; value: AUC score list\n",
    "policy_list = ['entropy', 'leastconfidence', 'random']\n",
    "# round_list = [1, 50, 100, 150, 200, 250, 300, 350, 400]\n",
    "round = 200\n",
    "\n",
    "for policy in policy_list:\n",
    "    eva_dict[policy] = AL_loop(X_train, y_train, X_val, y_val, X_test, y_test, policy, round = round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for policy in policy_list:\n",
    "    plt.plot(range(round)[::10], eva_dict[policy][::10], label = policy)\n",
    "plt.legend()\n",
    "plt.xlabel(\"# Active Learning Queries\")\n",
    "plt.ylabel(\"AUC score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN-Mirtron-Canonical-miRNA.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
